{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from seglearn.pipe import Pype\n",
    "from seglearn.transform import FeatureRep, Segment\n",
    "#from seglearn.feature_functions import mean, var, std, skew, kurt\n",
    "from seglearn.feature_functions import base_features, all_features\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB_data_path = \"./Data/Fanis_Balaskas/accel_gyro.csv\"\n",
    "GV_data_path = \"./Data/George_Vardakas/accel_gyro_Geo.csv\"\n",
    "ΤT_data_path = \"./Data/George_Vardakas/accel_gyro_Ted.csv\"\n",
    "GP_data_path = \"./Data/George_Vardakas/accel_gyro_Gregory.csv\"\n",
    "BRO_data_path = \"./Data/George_Vardakas/accel_gyro_Bro.csv\"\n",
    "VD_data_path = \"./Data/Vagelis_Dimoulis/accel_gyro.csv\"\n",
    "\n",
    "\n",
    "df_FB_accel_gyro = pd.read_csv(FB_data_path)\n",
    "df_GV_accel_gyro = pd.read_csv(GV_data_path)\n",
    "df_TT_accel_gyro = pd.read_csv(ΤT_data_path)\n",
    "df_GP_accel_gyro = pd.read_csv(GP_data_path)\n",
    "df_BRO_accel_gyro = pd.read_csv(BRO_data_path)\n",
    "df_VD_accel_gyro = pd.read_csv(VD_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Den exw ta ms gia na spasw to shma se kathgories\n",
    "datetime_format = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "df_FB_accel_gyro[\"TIMESTAMP\"] = pd.to_datetime(df_FB_accel_gyro[\"TIMESTAMP\"])#, format=datetime_format)\n",
    "df_GV_accel_gyro[\"TIMESTAMP\"] = pd.to_datetime(df_GV_accel_gyro[\"TIMESTAMP\"])#, format=datetime_format)\n",
    "df_TT_accel_gyro[\"TIMESTAMP\"] = pd.to_datetime(df_TT_accel_gyro[\"TIMESTAMP\"])\n",
    "df_GP_accel_gyro[\"TIMESTAMP\"] = pd.to_datetime(df_GP_accel_gyro[\"TIMESTAMP\"])\n",
    "df_BRO_accel_gyro[\"TIMESTAMP\"] = pd.to_datetime(df_BRO_accel_gyro[\"TIMESTAMP\"])\n",
    "df_VD_accel_gyro[\"TIMESTAMP\"] = pd.to_datetime(df_VD_accel_gyro[\"TIMESTAMP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find when activity changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling frequency of accelerometer and gyroscope (10 Hz)\n",
    "sampling_frequency = df_FB_accel_gyro.loc[1, \"TIMESTAMP\"] - df_FB_accel_gyro.loc[0, \"TIMESTAMP\"]\n",
    "\n",
    "# Finding the indexs where the samples differ more than sampling frequency\n",
    "df_FB_activity_cutoff = df_FB_accel_gyro.loc[df_FB_accel_gyro[\"TIMESTAMP\"] - df_FB_accel_gyro[\"TIMESTAMP\"].shift() > sampling_frequency]\n",
    "df_GV_activity_cutoff = df_GV_accel_gyro.loc[df_GV_accel_gyro[\"TIMESTAMP\"] - df_GV_accel_gyro[\"TIMESTAMP\"].shift() > sampling_frequency]\n",
    "df_TT_activity_cutoff = df_TT_accel_gyro.loc[df_TT_accel_gyro[\"TIMESTAMP\"] - df_TT_accel_gyro[\"TIMESTAMP\"].shift() > sampling_frequency]\n",
    "df_GP_activity_cutoff = df_GP_accel_gyro.loc[df_GP_accel_gyro[\"TIMESTAMP\"] - df_GP_accel_gyro[\"TIMESTAMP\"].shift() > sampling_frequency]\n",
    "df_BRO_activity_cutoff = df_BRO_accel_gyro.loc[df_BRO_accel_gyro[\"TIMESTAMP\"] - df_BRO_accel_gyro[\"TIMESTAMP\"].shift() > sampling_frequency]\n",
    "df_VD_activity_cutoff = df_VD_accel_gyro.loc[df_VD_accel_gyro[\"TIMESTAMP\"] - df_VD_accel_gyro[\"TIMESTAMP\"].shift() > sampling_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_GV_accel_gyro[[\"ACTIVITY_ID\", \"ACCEL_X\", \"ACCEL_Y\", \"ACCEL_Z\"]].plot(figsize = (15, 8))\n",
    "#ax.vlines(df_GV_activity_cutoff.index, ymin=-20, ymax=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_FB_accel_gyro[[\"ACTIVITY_ID\", \"ACCEL_X\", \"ACCEL_Y\", \"ACCEL_Z\"]].plot(figsize = (15, 8))\n",
    "#ax.vlines(df_FB_activity_cutoff.index, ymin=-20, ymax=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_VD_accel_gyro[[\"ACTIVITY_ID\", \"ACCEL_X\", \"ACCEL_Y\", \"ACCEL_Z\"]].plot(figsize = (15, 8))\n",
    "#ax.vlines(df_VD_activity_cutoff.index, ymin=-20, ymax=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_TT_accel_gyro[[\"ACTIVITY_ID\", \"ACCEL_X\", \"ACCEL_Y\", \"ACCEL_Z\"]].plot(figsize = (15, 8))\n",
    "#ax.vlines(df_TT_activity_cutoff.index, ymin=-20, ymax=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_GP_accel_gyro[[\"ACTIVITY_ID\", \"ACCEL_X\", \"ACCEL_Y\", \"ACCEL_Z\"]].plot(figsize = (15, 8))\n",
    "#ax.vlines(df_GP_activity_cutoff.index, ymin=-20, ymax=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_BRO_accel_gyro[[\"ACTIVITY_ID\", \"ACCEL_X\", \"ACCEL_Y\", \"ACCEL_Z\"]].plot(figsize = (15, 8))\n",
    "#ax.vlines(df_BRO_activity_cutoff.index, ymin=-20, ymax=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making one dataframe for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FB_accel_gyro[\"USER_ID\"] = 0\n",
    "df_GV_accel_gyro[\"USER_ID\"] = 1\n",
    "df_VD_accel_gyro[\"USER_ID\"] = 2\n",
    "df_TT_accel_gyro[\"USER_ID\"] = 3\n",
    "df_GP_accel_gyro[\"USER_ID\"] = 4\n",
    "df_BRO_accel_gyro[\"USER_ID\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accel_gyro = df_FB_accel_gyro.append(df_GV_accel_gyro)\n",
    "df_accel_gyro = df_accel_gyro.append(df_VD_accel_gyro)\n",
    "df_accel_gyro = df_accel_gyro.append(df_TT_accel_gyro)\n",
    "df_accel_gyro = df_accel_gyro.append(df_GP_accel_gyro)\n",
    "df_accel_gyro = df_accel_gyro.append(df_BRO_accel_gyro)\n",
    "df_accel_gyro.reset_index(inplace=True)\n",
    "del df_FB_accel_gyro, df_GV_accel_gyro, df_VD_accel_gyro, df_TT_accel_gyro, df_GP_accel_gyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_frequency = df_accel_gyro.loc[1, \"TIMESTAMP\"] - df_accel_gyro.loc[0, \"TIMESTAMP\"]\n",
    "# Finding the indexs where the samples differ more than sampling frequency\n",
    "activities = df_accel_gyro.loc[df_accel_gyro['TIMESTAMP'] - df_accel_gyro['TIMESTAMP'].shift() > sampling_frequency]\n",
    "# To include the last activity to the end\n",
    "activities = activities.append(df_accel_gyro.iloc[-1])\n",
    "\n",
    "# Constracting the data exactly how the seglearn needs it\n",
    "# Data must be list(np.arrays)\n",
    "# list() -> single multivariate time series\n",
    "# X[0].shape -> (n_samples, n_variables)\n",
    "# n_samples is how many data points we have in time we have\n",
    "# n_variables is how many sensors we have\n",
    "\n",
    "# I do not include the moment where activity changes\n",
    "X = list()\n",
    "y = list()\n",
    "groups = list()\n",
    "low_index = 0\n",
    "\n",
    "# Use this to throw some samples or not?\n",
    "samples_to_throw = 10\n",
    "\n",
    "for i, high_index in enumerate(activities.index):\n",
    "    low_index += samples_to_throw\n",
    "    high_index -= samples_to_throw\n",
    "    data = df_accel_gyro[[\"ACCEL_X\",\"ACCEL_Y\", \"ACCEL_Z\", \"GYRO_X\", \"GYRO_Y\", \"GYRO_Z\"]].iloc[low_index : high_index]\n",
    "    data = data.to_numpy()\n",
    "    labels = df_accel_gyro[\"ACTIVITY_ID\"].iloc[low_index]\n",
    "    user_id = df_accel_gyro[\"USER_ID\"].iloc[low_index]\n",
    "    \n",
    "    X.append(data)\n",
    "    y.append(labels)\n",
    "    groups.append(user_id)\n",
    "    \n",
    "    #print(low_index, mid_index, high_index)\n",
    "    low_index = high_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_accel_gyro[[\"ACCEL_X\",\"ACCEL_Y\", \"ACCEL_Z\", \"GYRO_X\", \"GYRO_Y\", \"GYRO_Z\", \"ACTIVITY_ID\", \"USER_ID\"]].plot(figsize=(15,8))\n",
    "#ax.vlines(activities.index, ymin=-20, ymax=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                               24599\n",
       "TIMESTAMP      2021-01-25 15:36:55.848000\n",
       "ACCEL_X                          -11.3465\n",
       "ACCEL_Y                          -7.87716\n",
       "ACCEL_Z                              3.68\n",
       "GYRO_X                            1.23255\n",
       "GYRO_Y                          -0.585913\n",
       "GYRO_Z                         -0.0767012\n",
       "ACTIVITY_ID                           102\n",
       "USER_ID                                 5\n",
       "Name: 332999, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accel_gyro.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the features and the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geo/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass memory=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/home/geo/.local/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pype([\n",
    "    (\"segment\", Segment()),\n",
    "    (\"features\", FeatureRep(features = base_features())),\n",
    "    #(\"features\", FeatureRep(features = all_features())),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "], memory=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geo/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass memory=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "/home/geo/.local/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    }
   ],
   "source": [
    "splitter = GroupKFold(n_splits=6)\n",
    "cv = splitter.split(X, y, groups)\n",
    "\n",
    "parameters_grid = {\"segment__width\": list(range(250, 400, 50)),\n",
    "                   \"segment__overlap\": np.arange(0.1, 0.3, 0.1).tolist(),\n",
    "                   \"pca__n_components\" : [56, 61, 66],\n",
    "                   \"rf__n_estimators\": range(20, 45, 5)\n",
    "                  }\n",
    "\n",
    "# scoring does not work for some reason\n",
    "# it maybe always say the big category for each fragment\n",
    "# scoring=\"accuracy\", maybe because random forest has out of bag error \n",
    "grid_search = GridSearchCV(pipeline, parameters_grid, cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation on the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "cv = splitter.split(X, y, groups)\n",
    "\n",
    "results = cross_validate(best_estimator, X, y, cv=cv, n_jobs=-1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, fold, normalize=True, cmap=plt.cm.Blues):\n",
    "    title = \"Confusion matrix \" + str(fold)\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    plt.figure(figsize = (15, 8))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.ylabel(\"True label\", fontsize=15)\n",
    "    plt.xlabel(\"Predicted label\", fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(graphs_path + title, facecolor = \"#E0E0E0\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the confusion matrix for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipe is only for data transformations\n",
    "transform_pipe = Pype([\n",
    "    (\"segment\", best_estimator.named_steps[\"segment\"]),\n",
    "    (\"features\", best_estimator.named_steps[\"features\"]),\n",
    "    (\"scaler\", best_estimator.named_steps[\"scaler\"]),\n",
    "    (\"pca\", best_estimator.named_steps[\"pca\"]),\n",
    "], memory=None)\n",
    "\n",
    "df_activities = pd.read_csv(\"./Data/HomoreDataFromVariousActivities/activities.csv\")\n",
    "\n",
    "cv = splitter.split(X, y, groups)\n",
    "for fold, split in enumerate(cv):\n",
    "    training_set, test_set = split\n",
    "    \n",
    "    # Spliting the to training and testing set\n",
    "    x_train, x_test = np.asarray(X)[training_set], np.asarray(X)[test_set]\n",
    "    y_train, y_test = np.asarray(y)[training_set], np.asarray(y)[test_set]\n",
    "    \n",
    "    visited = dict()\n",
    "    labels = list()\n",
    "    for yi_label in y_test:\n",
    "        if yi_label not in visited:\n",
    "            visited[yi_label] = True\n",
    "            labels.append(yi_label)\n",
    "    \n",
    "    print(x_test[0].shape)\n",
    "    # Transforming the test data to fit the model predictions\n",
    "    _, y_test_trans = transform_pipe.fit_transform(x_test, y_test)\n",
    "    \n",
    "    # Fiting the model\n",
    "    best_estimator.fit(x_train, y_train)\n",
    "    \n",
    "    # Predicting with trained model\n",
    "    y_pred = best_estimator.predict(x_test)\n",
    "    \n",
    "    # Printing accuracy score and confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_test_trans, y_pred, labels=labels)\n",
    "    clf_accuracy = accuracy_score(y_test_trans, y_pred)\n",
    "    \n",
    "    # Select the right labels and order them correcly\n",
    "    labels_names = df_activities.loc[df_activities[\"ACTIVITY_ID\"].isin(labels)]\n",
    "    labels_names = labels_names.iloc[pd.Categorical(labels_names[\"ACTIVITY_ID\"], categories = labels, ordered=True).argsort()]\n",
    "    labels_names = labels_names[\"NAME\"].to_list()\n",
    "    plot_confusion_matrix(confusion_mat, labels_names, fold, normalize=True)\n",
    "    \n",
    "    print(clf_accuracy)\n",
    "    print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
